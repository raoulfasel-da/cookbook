{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "og-_daIBbMMR"
   },
   "source": [
    "# MLFlow to UbiOps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_PBGgrFhGv7K"
   },
   "source": [
    "In this tutorial, we'll create a generic UbiOps deployment that can load any MLFlow model with the Python function flavor.\n",
    "This flavor is the default MLFlow model interface in Python, making it possible to load models with `mlflow.pyfunc.load_model` \n",
    "and perform predictions using the `predict` method.\n",
    "\n",
    "Each MLFlow experiment run outputs a model artifact, which contains the model and a `requirements.txt` file. We'll provide a script to package these \n",
    "into a UbiOps deployment, which can be deployed to UbiOps directly, or be extended with preprocessing or postprocessing\n",
    "scripts.\n",
    "\n",
    "Our model’s `predict` method can accept:\n",
    "\n",
    "1. A Pandas DataFrame\n",
    "2. A dictionary (`Dict[str, numpy.ndarray]`)\n",
    "\n",
    "Since UbiOps only supports JSON-serializable inputs and outputs (not DataFrames or tensors), we’ll include guidance on \n",
    "converting these data types to and from JSON strings. The UbiOps deployment will be configured with input/output fields \n",
    "of datatype `String`.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0Al5FbPxHhjB"
   },
   "source": [
    "## Tutorial structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B0QNxemPHq68"
   },
   "source": [
    "This tutorial will have the following structure:\n",
    "- Install packages\n",
    "- Train MLFlow model\n",
    "- Convert the model artifact to a UbiOps deployment\n",
    "- Upload deployment to UbiOps\n",
    "- Run Inference\n",
    "  - Pandas Dataframe\n",
    "  - Dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "r4tyQQk_AVDE"
   },
   "source": [
    "## Installing required packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ia-Afcf2Aafv"
   },
   "source": [
    "We will need the following packages to run the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "otb5LQZObBOf"
   },
   "source": [
    "%pip install -U mlflow[extras]\n",
    "%pip install -U pyyaml \n",
    "%pip install -U ubiops"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Anj32nmSDTkh"
   },
   "source": [
    "## Train MLFlow model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4kNtjKUfkX-r"
   },
   "source": [
    "Now, let's train our example MLFlow Model. This code snippet is directly copied from the [MLFlow Github examples](https://github.com/mlflow/mlflow/blob/959e8d90a13b62d755115501dede4531e157c1e7/examples/sklearn_elasticnet_wine/train.py),\n",
    "with some adjustments to make it work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RlW8t5Kakali"
   },
   "source": [
    "# The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "# P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "# Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import warnings\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Read the wine-quality csv file from the URL\n",
    "    csv_url = (\n",
    "        \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\"\n",
    "    )\n",
    "    try:\n",
    "        data = pd.read_csv(csv_url, sep=\";\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\n",
    "            \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\n",
    "        )\n",
    "\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "\n",
    "    alpha = 0.5\n",
    "    l1_ratio = 0.5\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        print(f\"Elasticnet model (alpha={alpha:f}, l1_ratio={l1_ratio:f}):\")\n",
    "        print(f\"  RMSE: {rmse}\")\n",
    "        print(f\"  MAE: {mae}\")\n",
    "        print(f\"  R2: {r2}\")\n",
    "\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        predictions = lr.predict(train_x)\n",
    "        signature = infer_signature(train_x, predictions)\n",
    "        input_example = np.array(test_x)[:5]\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        # Model registry does not work with file store\n",
    "        if tracking_url_type_store != \"file\":\n",
    "            # Register the model\n",
    "            # There are other ways to use the Model Registry, which depends on the use case,\n",
    "            # please refer to the doc for more information:\n",
    "            # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "            mlflow.sklearn.log_model(\n",
    "                lr, \"model\", registered_model_name=\"ElasticnetWineModel\", signature=signature\n",
    "            )\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(lr, \"model\", signature=signature)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "juKb-wXWrREZ"
   },
   "source": [
    "Try out different `alpha` and `l1_ratio` values to get different runs!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "P4lBhVU7DxTH"
   },
   "source": [
    "### Retrieve best run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJFSmGYdsUnV"
   },
   "source": [
    "Now it's time to retrieve the run with the smallest `RMSE`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-6dhr51mntst"
   },
   "source": [
    "runs = mlflow.search_runs(order_by=[\"metrics.rmse ASC\"])\n",
    "best_run = runs.iloc[0]\n",
    "print(best_run)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "psGzGdOLsrNj"
   },
   "source": [
    "## Convert to UbiOps deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cDCFeNJ-suS7"
   },
   "source": [
    "We will now deploy the best MLFlow model to UbiOps.\n",
    "\n",
    "Let's first set some global variables that will allow us to connect to our UbiOps project, and set the name and version\n",
    "name of the deployment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "API_TOKEN = \"<INSERT API_TOKEN WITH PROJECT EDITOR RIGHTS>\"\n",
    "PROJECT_NAME = \"<INSERT PROJECT NAME IN YOUR ACCOUNT>\"\n",
    "DEPLOYMENT_NAME = \"mlflow-auto-deployment\"\n",
    "VERSION_NAME = \"v1\"\n",
    "\n",
    "PATH_TO_MLFLOW_MODEL_ARTIFACT = os.path.join(best_run.artifact_uri, \"model\").replace(\"file://\", \"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OzqzKLI35iFf"
   },
   "source": [
    "### Creating the deployment package template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OKhbJazY5jzk"
   },
   "source": [
    "Now it's time to create our deployment directory and add the right files to it so we can load our MLFlow model.  \n",
    "UbiOps supports a `libraries` directory where dependencies can be included. This directory is added to the system `$PATH` \n",
    "variable, such that its contents can be easily imported.  \n",
    "\n",
    "As mentioned in the intro, UbiOps does not support the input types of the MLFlow Python flavor `predict` method natively. \n",
    "Therefore, we will add functions that will convert an input/output string to and from the input types in our `libraries`\n",
    "directory.  \n",
    "\n",
    "Both input types will be tested in the [Inference](#inference) section."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oAxze0DA4Kkr"
   },
   "source": [
    "!mkdir deployment_package\n",
    "!mkdir deployment_package/libraries"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vHIF1XHG4ZWC"
   },
   "source": [
    "%%writefile deployment_package/deployment.py\n",
    "\n",
    "import mlflow\n",
    "import numpy\n",
    "import pandas\n",
    "from convert_data import data_to_string, string_to_data\n",
    "\n",
    "\n",
    "class Deployment:\n",
    "    def __init__(self):\n",
    "        print(mlflow.__version__)\n",
    "        self.model = mlflow.pyfunc.load_model(\"./model\")\n",
    "\n",
    "    def request(self, data):\n",
    "        data_parsed = string_to_data(data[\"input\"])\n",
    "        print(f\"Input data type: {type(data_parsed)}\")\n",
    "        prediction = self.model.predict(data_parsed)\n",
    "        return {\"output\": data_to_string(prediction)}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%writefile deployment_package/requirements.txt\n",
    "\n",
    "mlflow\n",
    "numpy\n",
    "pandas"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8BF13sV04lnd"
   },
   "source": [
    "%%writefile deployment_package/libraries/convert_data.py\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def data_to_string(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        return json.dumps(data.to_dict())\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return json.dumps(data.tolist())\n",
    "    elif isinstance(data, dict) and all(isinstance(v, np.ndarray) for v in data.values()):\n",
    "        return json.dumps({k: v.tolist() for k, v in data.items()})\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type\")\n",
    "\n",
    "\n",
    "def string_to_data(data_str):\n",
    "    data_json = json.loads(data_str)\n",
    "    if isinstance(data_json, dict):\n",
    "        if all(isinstance(v, list) for v in data_json.values()):\n",
    "            return {k: np.array(v) for k, v in data_json.items()}\n",
    "        else:\n",
    "            return pd.DataFrame.from_dict(data_json)\n",
    "    elif isinstance(data_json, list):\n",
    "        return np.array(data_json)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dsZOcPYY6iLT"
   },
   "source": [
    "## Conversion functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "O-1Qkihr6n7t"
   },
   "source": [
    "The following function will convert your MLModel artifact to a UbiOps deployment.  \n",
    "The following steps are executed inside the function:\n",
    "\n",
    "1. A check is performed to see if the `python_function` is supported in the MLFlow model\n",
    "2. The `requirements.txt` of the MLFlow artifact is copied to the UbiOps deployment `requirements.txt`\n",
    "3. Other model files are copied to the deployment directory\n",
    "4. The deployment directory will be zipped\n",
    "5. The deployment directory will be deleted depending on the corresponding function input"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V6da7Vdz67Ab"
   },
   "source": [
    "import shutil\n",
    "\n",
    "import yaml\n",
    "\n",
    "\n",
    "def convert_to_deployment_package(path_to_model_artifact, new_deployment_package_name, remove_directory=True):\n",
    "    \"\"\"\n",
    "    Converts a MLFlow model to a deployment package that can be uploaded to UbiOps\n",
    "    :param path_to_model_artifact: Path to the MLFlow model artifact\n",
    "    :param new_deployment_package_name: Name of the new deployment package\n",
    "    :param remove_directory: Whether to remove the deployment directory after zipping\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if python_function exists under flavors in the MLmodel file\n",
    "    with open(f\"{path_to_model_artifact}/MLmodel\", \"r\") as f:\n",
    "        mlflow_yaml = yaml.safe_load(f)\n",
    "        if \"python_function\" not in mlflow_yaml[\"flavors\"]:\n",
    "            raise Exception(\"No python_function flavor found in MLmodel file\")\n",
    "\n",
    "    # Append requirements.txt from MLflow model to requirements.txt in deployment package at the beginning\n",
    "    # Double packages don't matter, pip will just ignore them in this case\n",
    "    with open(f\"{path_to_model_artifact}/requirements.txt\", \"r\") as f:\n",
    "        requirements = f.readlines()\n",
    "        with open(f\"{new_deployment_package_name}/requirements.txt\", \"r+\") as f2:\n",
    "            content = f2.read()\n",
    "            f2.seek(0)\n",
    "            f2.write(\"\".join(requirements) + \"\\n\" + content)\n",
    "\n",
    "    # Copy the model to the deployment package\n",
    "    shutil.copytree(path_to_model_artifact, f\"{new_deployment_package_name}/model\")\n",
    "\n",
    "    # Zip the deployment package including the directory\n",
    "    archive_location = shutil.make_archive(new_deployment_package_name, \"zip\", base_dir=new_deployment_package_name)\n",
    "\n",
    "    print(\"Deployment package created successfully\")\n",
    "\n",
    "    if remove_directory:\n",
    "        shutil.rmtree(new_deployment_package_name)\n",
    "\n",
    "    return archive_location"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M1CoMjsJ7mas"
   },
   "source": [
    "deployment_zip = convert_to_deployment_package(\n",
    "    path_to_model_artifact=PATH_TO_MLFLOW_MODEL_ARTIFACT,\n",
    "    new_deployment_package_name=\"deployment_package\",\n",
    "    remove_directory=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fLw-xLmIBKZA"
   },
   "source": [
    "## Upload to UbiOps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "P1crwesdBQFz"
   },
   "source": [
    "The following function will create a deployment in UbiOps and uploads the deployment package to it.  \n",
    "Don't hesitate to read through the function to see what's happening!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k7rk0yWbR18y"
   },
   "source": [
    "import ubiops\n",
    "\n",
    "configuration = ubiops.Configuration()\n",
    "# Configure API token authorization\n",
    "configuration.api_key['Authorization'] = API_TOKEN\n",
    "# Defining host is optional and defaults to \"https://api.ubiops.com/v2.1\"\n",
    "configuration.host = \"https://api.ubiops.com/v2.1\"\n",
    "\n",
    "client = ubiops.ApiClient(configuration)\n",
    "api_client = ubiops.CoreApi(client)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iKsT8so9BaqJ"
   },
   "source": [
    "# Create deployment\n",
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    description='MLFlow deployment',\n",
    "    input_type='structured',\n",
    "    output_type='structured',\n",
    "    input_fields=[{'name': 'input', 'data_type': 'string'}],\n",
    "    output_fields=[{'name': 'output', 'data_type': 'string'}],\n",
    "    labels={\"MLFlow\": \"auto-deployment\"},\n",
    ")\n",
    "api_client.deployments_create(project_name=PROJECT_NAME, data=deployment_template)\n",
    "\n",
    "# Create version\n",
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=VERSION_NAME,\n",
    "    environment='python3-11',\n",
    "    instance_type_group_name='2048 MB + 0.5 vCPU',\n",
    "    maximum_instances=1,\n",
    "    minimum_instances=0,\n",
    "    maximum_idle_time=1800,  # = 30 minutes\n",
    "    request_retention_mode='full'\n",
    ")\n",
    "api_client.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    data=version_template\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Upload deployment code\n",
    "upload_response = api_client.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=VERSION_NAME,\n",
    "    file=deployment_zip\n",
    ")\n",
    "print(upload_response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JrrxrIF0QAK9"
   },
   "source": [
    "Let's wait for the deployment to be done!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kjLszx1PQB1L"
   },
   "source": [
    "ubiops.utils.wait_for_deployment_version(\n",
    "    client=client,\n",
    "    project_name = PROJECT_NAME,\n",
    "    deployment_name = DEPLOYMENT_NAME,\n",
    "    version = VERSION_NAME\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0Np6MxtpWMmK"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-zxA8PrzWODD"
   },
   "source": [
    "Now it's time to run inference on the deployed MLFlow model inside UbiOps. Both input types will be shown:  \n",
    "\n",
    "1. Pandas Dataframe\n",
    "2. Dict[`str`, numpy array]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7V2UeEUtYX6F"
   },
   "source": [
    "The following functions will be used to convert every data type to/from a string, so every data type will be interpretable by UbiOps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Tm9tmgoYYngP"
   },
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def data_to_string(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        return json.dumps(data.to_dict())\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return json.dumps(data.tolist())\n",
    "    elif isinstance(data, dict) and all(isinstance(v, np.ndarray) for v in data.values()):\n",
    "        return json.dumps({k: v.tolist() for k, v in data.items()})\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type\")\n",
    "\n",
    "\n",
    "def string_to_data(data_str):\n",
    "    data_json = json.loads(data_str)\n",
    "    if isinstance(data_json, dict):\n",
    "        if all(isinstance(v, list) for v in data_json.values()):\n",
    "            return {k: np.array(v) for k, v in data_json.items()}\n",
    "        else:\n",
    "            return pd.DataFrame.from_dict(data_json)\n",
    "    elif isinstance(data_json, list):\n",
    "        return np.array(data_json)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "T5p2HdUEYDIB"
   },
   "source": [
    "### Pandas Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "notWtwndJAh9"
   },
   "source": [
    "In order to get a Pandas dataframe from the sample, we'll be grabbing the first 3 samples of the training set!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nif_JvJ6JThT"
   },
   "source": [
    "data_pandas = train_x[:3]\n",
    "print(data_pandas)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "URR_3ugnQsyQ"
   },
   "source": [
    "Let's transfer our Pandas dataframe to a string, so we can make a request to our deployment!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-rOQPchzQ0Qy"
   },
   "source": [
    "data_pandas_string = data_to_string(data_pandas)\n",
    "print(data_pandas_string)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib3PR1TuRCJN"
   },
   "source": [
    "Now, let's send this string to our deployment!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ORsR8cErRSjE"
   },
   "source": [
    "result = api_client.deployment_version_requests_create(\n",
    "  project_name=PROJECT_NAME,\n",
    "  deployment_name=DEPLOYMENT_NAME,\n",
    "  version=VERSION_NAME,\n",
    "  data={\"input\": data_pandas_string}    \n",
    ")\n",
    "print(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vaufsa4FTbb6"
   },
   "source": [
    "As we can see, we get a perfect output back!  \n",
    "We can even convert the string back to an usable data type!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AJevZlaETp-4"
   },
   "source": [
    "print(f\"Original data type: {type(data_pandas)}\")\n",
    "print(f\"Output of UbiOps request is: {type(result.result['output'])}\")\n",
    "result_converted = string_to_data(result.result[\"output\"])\n",
    "print(f\"Output after conversion: {result_converted}\")\n",
    "print(f\"Type after conversion: {type(result_converted)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BMzt62Bl-6L_"
   },
   "source": [
    "### Dict[`str`, numpy array]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gZ95AT-w--om"
   },
   "source": [
    "data_dict = {k: np.array(v) for k, v in data_pandas.to_dict(orient=\"list\").items()}\n",
    "data_dict_string = data_to_string(data_dict)\n",
    "\n",
    "result = api_client.deployment_version_requests_create(\n",
    "  project_name=PROJECT_NAME,\n",
    "  deployment_name=DEPLOYMENT_NAME,\n",
    "  version=VERSION_NAME,\n",
    "  data={\"input\": data_dict_string}    \n",
    ")\n",
    "\n",
    "print(f\"Original data type: {type(data_dict)}\")\n",
    "print(f\"Output of UbiOps request is: {type(result.result['output'])}\")\n",
    "result_converted = string_to_data(result.result[\"output\"])\n",
    "print(f\"Output after conversion: {result_converted}\")\n",
    "print(f\"Type after conversion: {type(result_converted)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's it! We have now created a generic deployment template that we can use to host MLFlow models of Python function \n",
    "flavor, which can take multiple input format. This set-up serves as an example. You can always customize and extend the \n",
    "set-up. Feel free to reach out to our [Support channel](https://support.ubiops.com) if you want to have a discussion with our team"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
