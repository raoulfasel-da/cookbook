{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow template\n",
    "Note: This notebook runs on Python 3.12 and uses UbiOps Client Library 4.5.1.\n",
    "\n",
    "In this notebook we show you how to deploy a TensorFlow model to UbiOps. \n",
    "\n",
    "The TensorFlow model makes predictions on the fuel efficiency of late-1970s and early 1980s automobiles.\n",
    "\n",
    "This example uses [the classic Auto MPG dataset](http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data).\n",
    "\n",
    "\n",
    "If you run this entire notebook after filling in your access token, the TensorFlow deployment will be deployed to your UbiOps environment. You can check your environment after running to explore the results. You can also check the individual steps in this notebook to see what we did exactly and how you can adapt it to your own solution.\n",
    "\n",
    "We recommend to run the cells step by step, as some cells can take a few minutes to finish. You can run everything in one go as well and it will work, just allow a few minutes for building the individual deployments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Establishing a connection with your UbiOps environment\n",
    "\n",
    "We require an API Token with project editor rights to complete this tutorial. The final TensorFlow model ends up in a deployment with a name of choice and a version. We define these parameters and connect to our API Client. Using this connection, we can interact with our project. Finally, we initiate a local empty directory that we can use to host our deployment files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "API_TOKEN = \"<INSERT API_TOKEN WITH PROJECT EDITOR RIGHTS>\"\n",
    "PROJECT_NAME = \"<INSERT PROJECT NAME IN YOUR ACCOUNT>\"\n",
    "DEPLOYMENT_NAME = \"tensorflow-deployment\"\n",
    "DEPLOYMENT_VERSION = \"v1\"\n",
    "\n",
    "# Import all necessary libraries\n",
    "import shutil\n",
    "import os\n",
    "import ubiops\n",
    "\n",
    "client = ubiops.ApiClient(\n",
    "    ubiops.Configuration(\n",
    "        api_key={\"Authorization\": API_TOKEN}, host=\"https://api.ubiops.com/v2.1\"\n",
    "    )\n",
    ")\n",
    "api = ubiops.CoreApi(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the model\n",
    "\n",
    "This example will be based on the [regression tutorial from tensorflow](https://tensorflow.org/tutorials/keras/regression#get_the_data).\n",
    "\n",
    "In this document we focus on deploying the model to UbiOps rather than on developing a model. Without elaborating much, we train a simple model and save the resulting file to our deployment package directory.\n",
    "\n",
    "Let us first install the python packages we need for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ubiops==4.5.1\n",
    "!pip install pandas==2.2.2\n",
    "!pip install numpy==2.1.1\n",
    "!pip install tensorflow==2.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Normalization\n",
    "\n",
    "# Predict the fuel efficiency of late-1970s and early 1980s automobiles\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# Load data\n",
    "column_names = [\n",
    "    \"MPG\",\n",
    "    \"Cylinders\",\n",
    "    \"Displacement\",\n",
    "    \"Horsepower\",\n",
    "    \"Weight\",\n",
    "    \"Acceleration\",\n",
    "    \"Model Year\",\n",
    "    \"Origin\",\n",
    "]\n",
    "raw_dataset = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/ubiops/data/Deploying%20with%20popular%20DS%20libraries/tensorflow-example/auto-mpg.csv\",\n",
    "    names=column_names,\n",
    "    na_values=\"?\",\n",
    "    comment=\"\\t\",\n",
    "    sep=\" \",\n",
    "    skipinitialspace=True,\n",
    ")\n",
    "dataset = raw_dataset.copy()\n",
    "\n",
    "# Drop all but the horsepower and mpg columns\n",
    "dataset = dataset[[\"Horsepower\", \"MPG\"]]\n",
    "\n",
    "# Drop unknown value rows\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# Split into train and test set 80-20\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "# Checking how our data structure looks like\n",
    "print(\"Data:\")\n",
    "print(train_dataset.describe().transpose())\n",
    "\n",
    "# Separate the target value, the \"label\", from the features. This label is the value that you will train the model to predict.\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop(\"MPG\")\n",
    "test_labels = test_features.pop(\"MPG\")\n",
    "\n",
    "\n",
    "# Create the horsepower Normalization layer:\n",
    "horsepower = np.array(train_features)\n",
    "horsepower_normalizer = Normalization(\n",
    "    input_shape=[\n",
    "        1,\n",
    "    ]\n",
    ")\n",
    "horsepower_normalizer.adapt(horsepower)\n",
    "\n",
    "# Build the sequential model\n",
    "model = tf.keras.Sequential([horsepower_normalizer, layers.Dense(units=1)])\n",
    "\n",
    "# Configure training procedure\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1), loss=\"mean_absolute_error\"\n",
    ")\n",
    "\n",
    "# Train the model using the prepared data\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    # suppress logging\n",
    "    verbose=0,\n",
    "    # Calculate validation results on 20% of the training data\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "# Calculate mean absolute error\n",
    "mae = model.evaluate(test_features, test_labels, verbose=0)\n",
    "\n",
    "print(f\"The mean absolute error of the model is {mae}\")\n",
    "\n",
    "# Save our new model in this directory in a zipped state\n",
    "model.save(\"tensorflow_model.keras\")\n",
    "\n",
    "print(\"Model created and saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating the tensorflow deployment\n",
    "Now that we have our model saved it is time to create a deployment in UbiOps that will make use of it.\n",
    "\n",
    "In the cell below the deployment.py which will take the data we wish to predict the MPG for. As you can see in the initialization step we load the model we created earlier, then in the request method we make use of it to make a prediction. Input to this model is:\n",
    "\n",
    "* data: a csv file with the data to predict the MPG (mile per gallon)\n",
    "\n",
    "The output of this model is:\n",
    "\n",
    "* data: a keras file that can predict the MPG (mile per gallon) based on several parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a local directory and move our model there\n",
    "os.mkdir(\"tensorflow_deployment_package\")\n",
    "shutil.move(\n",
    "    \"./tensorflow_model.keras\", \"./tensorflow_deployment_package/tensorflow_model.keras\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tensorflow_deployment_package/deployment.py\n",
    "\"\"\"\n",
    "The file containing the deployment code is required to be called 'deployment.py' and should contain the 'Deployment'\n",
    "class and 'request' method.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class Deployment:\n",
    "\n",
    "    def __init__(self, base_directory, context):\n",
    "        \"\"\"\n",
    "        Initialisation method for the deployment. It can for example be used for loading modules that have to be kept in\n",
    "        memory or setting up connections. Load your external model files (such as pickles or .h5 files) here.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Initialising the model\")\n",
    "\n",
    "        model_file = os.path.join(base_directory, \"tensorflow_model.keras\")\n",
    "        self.model = load_model(model_file)\n",
    "\n",
    "\n",
    "    def request(self, data):\n",
    "        \"\"\"\n",
    "        Method for deployment requests, called separately for each individual request.\n",
    "\n",
    "        \"\"\"\n",
    "        print('Loading data')\n",
    "        input_data = pd.read_csv(data['data'])\n",
    "        \n",
    "        print(\"Prediction being made\")\n",
    "        prediction = self.model.predict(input_data)\n",
    "        \n",
    "        # Writing the prediction to a csv for further use\n",
    "        print('Writing prediction to csv')\n",
    "        pd.DataFrame(prediction).to_csv('prediction.csv', header = ['MPG'], index_label= 'index')\n",
    "        \n",
    "        return {\n",
    "            \"prediction\": 'prediction.csv',\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tensorflow_deployment_package/requirements.txt\n",
    "\n",
    "tensorflow==2.17.0\n",
    "pandas==2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploying to UbiOps\n",
    "\n",
    "Now we have all the pieces we need to create our deployment on UbiOps. In the cell below we show how to create a deployment, how to create a version of the deployment and how to upload our deployment code to the deployment version.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the deployment\n",
    "deployment_template = ubiops.DeploymentCreate(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    description=\"Tensorflow deployment\",\n",
    "    input_type=\"structured\",\n",
    "    output_type=\"structured\",\n",
    "    input_fields=[{\"name\": \"data\", \"data_type\": \"file\"}],\n",
    "    output_fields=[{\"name\": \"prediction\", \"data_type\": \"file\"}],\n",
    "    labels={\"demo\": \"tensorflow\"},\n",
    ")\n",
    "\n",
    "api.deployments_create(project_name=PROJECT_NAME, data=deployment_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ubiops import utils\n",
    "\n",
    "# Create the version\n",
    "version_template = ubiops.DeploymentVersionCreate(\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    environment=\"python3-12\",\n",
    "    instance_type_group_name=\"512 MB + 0.125 vCPU\",\n",
    "    minimum_instances=0,\n",
    "    maximum_instances=1,\n",
    "    maximum_idle_time=1800,  # = 30 minutes\n",
    "    request_retention_mode=\"full\",\n",
    ")\n",
    "\n",
    "api.deployment_versions_create(\n",
    "    project_name=PROJECT_NAME, deployment_name=DEPLOYMENT_NAME, data=version_template\n",
    ")\n",
    "\n",
    "# Zip the deployment package\n",
    "shutil.make_archive(\n",
    "    \"./tensorflow_deployment_package\", \"zip\", \"./tensorflow_deployment_package\"\n",
    ")\n",
    "\n",
    "\n",
    "# Upload the zipped deployment package\n",
    "file_upload_result = api.revisions_file_upload(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    file=\"tensorflow_deployment_package.zip\",\n",
    ")\n",
    "\n",
    "# Wait for deployment version\n",
    "ubiops.utils.wait_for_deployment_version(\n",
    "    client=client,\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    revision_id=file_upload_result.revision,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making a request to your deployment\n",
    "\n",
    "You can now visit the Web App and explore the user interface to see what you've just built. In the code below you can create a request using a dummy dataset which is just the horsepower data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data to local storage\n",
    "!wget -O dummy_data_to_predict.csv \"https://storage.googleapis.com/ubiops/data/Deploying%20with%20popular%20DS%20libraries/tensorflow-example/dummy_data_to_predict.csv\"\n",
    "\n",
    "# Upload the data to the bucket\n",
    "file_uri = ubiops.utils.upload_file(\n",
    "    client=client,\n",
    "    project_name=PROJECT_NAME,\n",
    "    file_path=\"./dummy_data_to_predict.csv\",\n",
    "    bucket_name=\"default\",\n",
    "    file_name=\"tensorflow-example/dummy_data_to_predict.csv\",\n",
    ")\n",
    "\n",
    "# Put the data in the right format\n",
    "data = {\"data\": file_uri}\n",
    "\n",
    "# Create a request using the API, the result can be found in the 'default' bucket\n",
    "api.deployment_version_requests_create(\n",
    "    project_name=PROJECT_NAME,\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    version=DEPLOYMENT_VERSION,\n",
    "    data=data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. All done! Let's close the client properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exploring further\n",
    "\n",
    "We have created a deployment that hosts a TensorFlow model.You can use this notebook to base your own deployments on. Just adapt the code in the deployment packages and alter the input and output fields as you wish and you should be good to go.\n",
    "\n",
    "For any questions, feel free to reach out to us via the customer service portal: https://ubiops.atlassian.net/servicedesk/customer/portals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
